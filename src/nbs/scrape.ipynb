{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/cfe/Dev/jupyter-api/lib/python3.9/site-packages (2.25.1)\n",
      "Collecting requests-html\n",
      "  Using cached requests_html-0.10.0-py3-none-any.whl (13 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.2.4-cp39-cp39-macosx_10_9_x86_64.whl (10.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.7 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /Users/cfe/Dev/jupyter-api/lib/python3.9/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/cfe/Dev/jupyter-api/lib/python3.9/site-packages (from requests) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/cfe/Dev/jupyter-api/lib/python3.9/site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/cfe/Dev/jupyter-api/lib/python3.9/site-packages (from requests) (1.26.4)\n",
      "Collecting pyquery\n",
      "  Downloading pyquery-1.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting fake-useragent\n",
      "  Using cached fake-useragent-0.1.11.tar.gz (13 kB)\n",
      "Collecting pyppeteer>=0.0.14\n",
      "  Downloading pyppeteer-0.2.5-py3-none-any.whl (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 2.6 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting parse\n",
      "  Downloading parse-1.19.0.tar.gz (30 kB)\n",
      "Collecting w3lib\n",
      "  Using cached w3lib-1.22.0-py2.py3-none-any.whl (20 kB)\n",
      "Collecting bs4\n",
      "  Using cached bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/cfe/Dev/jupyter-api/lib/python3.9/site-packages (from pandas) (2.8.1)\n",
      "Collecting numpy>=1.16.5\n",
      "  Downloading numpy-1.20.2-cp39-cp39-macosx_10_9_x86_64.whl (16.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.1 MB 6.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2017.3\n",
      "  Using cached pytz-2021.1-py2.py3-none-any.whl (510 kB)\n",
      "Collecting cssselect>0.7.9\n",
      "  Using cached cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting lxml>=2.1\n",
      "  Downloading lxml-4.6.3-cp39-cp39-macosx_10_9_x86_64.whl (4.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6 MB 8.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm<5.0.0,>=4.42.1 in /Users/cfe/Dev/jupyter-api/lib/python3.9/site-packages (from pyppeteer>=0.0.14->requests-html) (4.60.0)\n",
      "Requirement already satisfied: appdirs<2.0.0,>=1.4.3 in /Users/cfe/Dev/jupyter-api/lib/python3.9/site-packages (from pyppeteer>=0.0.14->requests-html) (1.4.4)\n",
      "Collecting pyee<9.0.0,>=8.1.0\n",
      "  Downloading pyee-8.1.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting websockets<9.0,>=8.1\n",
      "  Downloading websockets-8.1.tar.gz (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 6.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.4.1 in /Users/cfe/Dev/jupyter-api/lib/python3.9/site-packages (from w3lib->requests-html) (1.15.0)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.9.3-py3-none-any.whl (115 kB)\n",
      "Collecting soupsieve>1.2; python_version >= \"3.0\"\n",
      "  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
      "Using legacy 'setup.py install' for fake-useragent, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for parse, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for bs4, since package 'wheel' is not installed.\n",
      "Using legacy 'setup.py install' for websockets, since package 'wheel' is not installed.\n",
      "Installing collected packages: cssselect, lxml, pyquery, fake-useragent, pyee, websockets, pyppeteer, parse, w3lib, soupsieve, beautifulsoup4, bs4, requests-html, numpy, pytz, pandas\n",
      "    Running setup.py install for fake-useragent ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for websockets ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for parse ... \u001b[?25ldone\n",
      "\u001b[?25h    Running setup.py install for bs4 ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed beautifulsoup4-4.9.3 bs4-0.0.1 cssselect-1.1.0 fake-useragent-0.1.11 lxml-4.6.3 numpy-1.20.2 pandas-1.2.4 parse-1.19.0 pyee-8.1.0 pyppeteer-0.2.5 pyquery-1.4.3 pytz-2021.1 requests-html-0.10.0 soupsieve-2.2.1 w3lib-1.22.0 websockets-8.1\n",
      "\u001b[33mWARNING: You are using pip version 20.2.3; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/Users/cfe/Dev/jupyter-api/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install requests requests-html pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "import requests\n",
    "from requests_html import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ScrapeBoxOffice:\n",
    "    base_endpoint:str = \"https://www.boxofficemojo.com/year/world/\"\n",
    "    year:int = None\n",
    "    save_raw:bool = False\n",
    "    save:bool = False\n",
    "    output_dir: str = \".\"\n",
    "    table_selector: str = '.imdb-scroll-table'\n",
    "    table_data = []\n",
    "    table_header_names = []\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.year if isinstance(self.year, int) else 'world'\n",
    "    \n",
    "    def get_endpoint(self):\n",
    "        endpoint = self.base_endpoint\n",
    "        if isinstance(self.year, int):\n",
    "            endpoint = f\"{endpoint}{self.year}/\"\n",
    "        return endpoint\n",
    "    \n",
    "    def get_output_dir(self):\n",
    "        return pathlib.Path(self.output_dir)\n",
    "    \n",
    "    def extract_html_str(self, endpoint=None):\n",
    "        url = endpoint if endpoint is not None else self.get_endpoint()\n",
    "        r = requests.get(url, stream=True)\n",
    "        html_text = None\n",
    "        status = r.status_code\n",
    "        if r.status_code == 200:\n",
    "            html_text = r.text\n",
    "            if self.save_raw:\n",
    "                output_fname = f\"{self.name}.html\"\n",
    "                raw_output_dir = self.get_output_dir() / 'html'\n",
    "                raw_output_dir.mkdir(exist_ok=True, parents=True)\n",
    "                output_fname = raw_output_dir / output_fname\n",
    "                with open(f\"{output_fname}\", 'w') as f:\n",
    "                    f.write(html_text)\n",
    "            return html_text, status\n",
    "        return html_text, status\n",
    "    \n",
    "    def parse_html(self, html_str=''):\n",
    "        r_html = HTML(html=html_str)\n",
    "        r_table = r_html.find(self.table_selector)\n",
    "        if len(r_table) == 0:\n",
    "            return None\n",
    "        table_data = []\n",
    "        header_names = []\n",
    "        parsed_table = r_table[0]\n",
    "        rows = parsed_table.find(\"tr\")\n",
    "        header_row = rows[0]\n",
    "        header_cols = header_row.find('th')\n",
    "        header_names = [x.text for x in header_cols]\n",
    "        for row in rows[1:]:\n",
    "            cols = row.find(\"td\")\n",
    "            row_data = []\n",
    "            row_dict_data = {}\n",
    "            for i, col in enumerate(cols):\n",
    "                header_name = header_names[i]\n",
    "                row_data.append(col.text)\n",
    "            table_data.append(row_data)\n",
    "        self.table_data = table_data\n",
    "        self.table_header_names = header_names\n",
    "        return self.table_data, self.table_header_names\n",
    "    \n",
    "    def to_df(self, data=[], columns=[]):\n",
    "        return pd.DataFrame(data, columns=columns)\n",
    "    \n",
    "    def run(self, save=False):\n",
    "        save = self.save if save is False else save\n",
    "        endpoint = self.get_endpoint()\n",
    "        html_str, status = self.extract_html_str(endpoint=endpoint)\n",
    "        if status not in range(200, 299):\n",
    "            raise Exception(f\"Extraction failed, endpoint status {status} at {endpoint}\")\n",
    "        data, headers = self.parse_html(html_str if html_str is not None else '')\n",
    "        df = self.to_df(data=data, columns=headers)\n",
    "        self.df = df\n",
    "        if save:\n",
    "            filepath = self.get_output_dir() / f'{self.name}.csv'\n",
    "            df.to_csv(filepath, index=False)\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Release Group</th>\n",
       "      <th>Worldwide</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>%</th>\n",
       "      <th>Foreign</th>\n",
       "      <th>%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story 3</td>\n",
       "      <td>$1,066,969,703</td>\n",
       "      <td>$415,004,880</td>\n",
       "      <td>38.9%</td>\n",
       "      <td>$651,964,823</td>\n",
       "      <td>61.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Alice in Wonderland</td>\n",
       "      <td>$1,025,467,110</td>\n",
       "      <td>$334,191,110</td>\n",
       "      <td>32.6%</td>\n",
       "      <td>$691,276,000</td>\n",
       "      <td>67.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 1</td>\n",
       "      <td>$976,536,918</td>\n",
       "      <td>$295,983,305</td>\n",
       "      <td>30.3%</td>\n",
       "      <td>$680,553,613</td>\n",
       "      <td>69.7%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Inception</td>\n",
       "      <td>$826,137,188</td>\n",
       "      <td>$292,576,195</td>\n",
       "      <td>35.4%</td>\n",
       "      <td>$533,560,993</td>\n",
       "      <td>64.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Shrek Forever After</td>\n",
       "      <td>$752,600,867</td>\n",
       "      <td>$238,736,787</td>\n",
       "      <td>31.7%</td>\n",
       "      <td>$513,864,080</td>\n",
       "      <td>68.3%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Rank                                 Release Group       Worldwide  \\\n",
       "0    1                                   Toy Story 3  $1,066,969,703   \n",
       "1    2                           Alice in Wonderland  $1,025,467,110   \n",
       "2    3  Harry Potter and the Deathly Hallows: Part 1    $976,536,918   \n",
       "3    4                                     Inception    $826,137,188   \n",
       "4    5                           Shrek Forever After    $752,600,867   \n",
       "\n",
       "       Domestic      %       Foreign      %  \n",
       "0  $415,004,880  38.9%  $651,964,823  61.1%  \n",
       "1  $334,191,110  32.6%  $691,276,000  67.4%  \n",
       "2  $295,983,305  30.3%  $680,553,613  69.7%  \n",
       "3  $292,576,195  35.4%  $533,560,993  64.6%  \n",
       "4  $238,736,787  31.7%  $513,864,080  68.3%  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraper = ScrapeBoxOffice(year=2010, save=True, save_raw=True, output_dir='data')\n",
    "df = scraper.run()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
